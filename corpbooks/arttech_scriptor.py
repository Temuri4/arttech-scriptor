#!/usr/bin/env python3
"""
Arttech Scriptor - –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∫–Ω–∏–≥.

–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã:
- /list - —Å–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π
- /info <–∫–æ–¥> - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ meta.json
- /get <–∫–æ–¥> <—Ñ–∞–π–ª> - –≤—ã–¥–∞—á–∞ —Ñ–∞–π–ª–æ–≤
- /ask [<–∫–æ–¥>] <–≤–æ–ø—Ä–æ—Å> - GPT-–ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ
- /deadlines - –±–ª–∏–∂–∞–π—à–∏–µ —Å—Ä–æ–∫–∏
- /my - –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥ –∫–æ–º–∞–Ω–¥:
- –ß–µ—Ä–µ–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª: python arttech_scriptor.py --voice file.wav
- –ß–µ—Ä–µ–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω: python arttech_scriptor.py --mic <–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_–≤_—Å–µ–∫—É–Ω–¥–∞—Ö>
"""

import os
import json
import glob
import datetime
import pickle
import re
import logging
import numpy as np
import tempfile
import wave
from typing import Dict, List, Optional, Tuple, Any, Union, Set
from pathlib import Path
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv
import openai

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4")
OPENAI_AVAILABLE = bool(OPENAI_API_KEY)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("arttech_scriptor")

class UnknownCommandError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–∞–Ω–¥."""
    pass

def get_whisper_model():
    """
    –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper.
    
    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ Whisper
    """
    global _WHISPER_MODEL
    
    if _WHISPER_MODEL is None:
        try:
            from faster_whisper import WhisperModel
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper (–∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–ª–µ–Ω—å–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç—ã)
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper...")
            _WHISPER_MODEL = WhisperModel("tiny", device="cpu", compute_type="int8")
            logger.info("–ú–æ–¥–µ–ª—å Whisper —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        except ImportError:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å faster_whisper. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É: pip install faster-whisper")
            raise
    
    return _WHISPER_MODEL

def transcribe_audio(audio_path):
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –≤ —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é Whisper.
    
    Args:
        audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        
    Returns:
        –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    try:
        model = get_whisper_model()
        
        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
        logger.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∏–∑ —Ñ–∞–π–ª–∞: {audio_path}")
        segments, info = model.transcribe(audio_path, language="ru")
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
        text = " ".join([segment.text for segment in segments])
        
        logger.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {text}")
        return text.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏: {e}")
        raise

def record_audio(duration=5, sample_rate=16000):
    """
    –ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞.
    
    Args:
        duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
        
    Returns:
        –ü—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É —Å –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–º –∞—É–¥–∏–æ
    """
    try:
        import sounddevice as sd
        
        logger.info(f"–ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ ({duration} —Å–µ–∫)...")
        
        # –ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ
        recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')
        sd.wait()  # –û–∂–∏–¥–∞–Ω–∏–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è –∑–∞–ø–∏—Å–∏
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ
        temp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        temp_path = temp_file.name
        temp_file.close()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—É–¥–∏–æ –≤ WAV-—Ñ–∞–π–ª
        with wave.open(temp_path, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16 –±–∏—Ç
            wf.setframerate(sample_rate)
            wf.writeframes(recording.tobytes())
        
        logger.info(f"–ê—É–¥–∏–æ –∑–∞–ø–∏—Å–∞–Ω–æ –≤ —Ñ–∞–π–ª: {temp_path}")
        return temp_path
    except ImportError:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å sounddevice. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É: pip install sounddevice")
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ: {e}")
        raise

def process_voice_command(audio_path=None, mic_duration=None):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã.
    
    Args:
        audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É —Å –∫–æ–º–∞–Ω–¥–æ–π
        mic_duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã
    """
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –∞—É–¥–∏–æ
        if audio_path:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª
            path_to_process = audio_path
            temp_file = None
        elif mic_duration:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
            path_to_process = record_audio(duration=mic_duration)
            temp_file = path_to_process
        else:
            raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –∏–ª–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç
        text = transcribe_audio(path_to_process)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω
        if temp_file and os.path.exists(temp_file):
            os.unlink(temp_file)
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        if not text:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∫–æ–º–∞–Ω–¥—É. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ."
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        assistant = ArttechScriptor()
        
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–∞–∫ –∫–æ–º–∞–Ω–¥—É
            result = assistant.process_command(text)
            return f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {text}\n\n{result}"
        except UnknownCommandError:
            clarification = assistant.clarify_command(text)
            return f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {text}\n\n{clarification}"
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã: {e}")
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã: {str(e)}"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã: {e}")
        return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã: {str(e)}"


class ArttechScriptor:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ Arttech Scriptor –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –∫–Ω–∏–≥–∞–º–∏.
    """
    
    def __init__(self, base_path: str = "/home/temo/HyperCyfra/projects/arttech-scriptor/corpbooks"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
        
        Args:
            base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –∫–Ω–∏–≥–∞–º–∏
        """
        self.base_path = Path(base_path)
        self.user_data = {}  # –í –±—É–¥—É—â–µ–º –∑–¥–µ—Å—å –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        self.embeddings_cache_path = self.base_path / ".embeddings_cache.pkl"
        self.embeddings_cache = self._load_embeddings_cache()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if not self.base_path.exists():
            logger.error(f"–ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {self.base_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {self.base_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    def _load_embeddings_cache(self) -> Dict[str, Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ embeddings –∏–∑ —Ñ–∞–π–ª–∞.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ embeddings
        """
        if self.embeddings_cache_path.exists():
            try:
                with open(self.embeddings_cache_path, 'rb') as f:
                    return pickle.load(f)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫—ç—à embeddings: {e}")
        return {}
    
    def _save_embeddings_cache(self) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫—ç—à–∞ embeddings –≤ —Ñ–∞–π–ª.
        """
        try:
            with open(self.embeddings_cache_path, 'wb') as f:
                pickle.dump(self.embeddings_cache, f)
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à embeddings: {e}")
    
    def get_companies(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ –±–∞–∑—ã.
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–º–ø–∞–Ω–∏—è—Ö
        """
        companies = []
        
        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∫–æ–º–ø–∞–Ω–∏–π
        company_dirs = [d for d in self.base_path.iterdir() if d.is_dir()]
        
        for company_dir in company_dirs:
            meta_path = company_dir / "meta.json"
            
            if meta_path.exists():
                try:
                    with open(meta_path, 'r', encoding='utf-8') as f:
                        meta_data = json.load(f)
                        
                    companies.append({
                        "code": meta_data.get("company_code", company_dir.name),
                        "name": meta_data.get("name", company_dir.name),
                        "status": meta_data.get("status", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                        "description": meta_data.get("short_description", "")
                    })
                except json.JSONDecodeError:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ meta.json –¥–ª—è {company_dir.name}")
                    companies.append({
                        "code": company_dir.name,
                        "name": company_dir.name,
                        "status": "–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è meta.json",
                        "description": ""
                    })
            else:
                # –ï—Å–ª–∏ meta.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                companies.append({
                    "code": company_dir.name,
                    "name": company_dir.name,
                    "status": "–ù–µ—Ç meta.json",
                    "description": ""
                })
        
        return companies
    
    def get_company_info(self, company_code: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏.
        
        Args:
            company_code: –ö–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–º–ø–∞–Ω–∏–∏
            
        Raises:
            FileNotFoundError: –ï—Å–ª–∏ –∫–æ–º–ø–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        """
        company_dir = self.base_path / company_code
        meta_path = company_dir / "meta.json"
        
        if not company_dir.exists():
            raise FileNotFoundError(f"–ö–æ–º–ø–∞–Ω–∏—è —Å –∫–æ–¥–æ–º {company_code} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        if not meta_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª meta.json –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ {company_code} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        try:
            with open(meta_path, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            structure = {
                "raw_files": len(list((company_dir / "01_raw").glob("*"))) if (company_dir / "01_raw").exists() else 0,
                "processed_files": len(list((company_dir / "02_processed").glob("*"))) if (company_dir / "02_processed").exists() else 0,
                "assets": len(list((company_dir / "03_assets").glob("*"))) if (company_dir / "03_assets").exists() else 0
            }
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è summary.md
            summary_exists = (company_dir / "summary.md").exists()
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            info = {
                **meta_data,
                "structure": structure,
                "summary_exists": summary_exists
            }
            
            return info
            
        except json.JSONDecodeError:
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ meta.json –¥–ª—è {company_code}")
    
    def get_file_content(self, company_code: str, file_path: str) -> Tuple[str, str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞.
        
        Args:
            company_code: –ö–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞, —Ç–∏–ø —Ñ–∞–π–ª–∞)
            
        Raises:
            FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        company_dir = self.base_path / company_code
        
        if not company_dir.exists():
            raise FileNotFoundError(f"–ö–æ–º–ø–∞–Ω–∏—è —Å –∫–æ–¥–æ–º {company_code} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏
        if file_path.startswith('/'):
            file_path = file_path[1:]
        
        full_path = company_dir / file_path
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫—É –≤—ã—Ö–æ–¥–∞ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏
        if not str(full_path).startswith(str(company_dir)):
            raise ValueError(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É: {file_path}")
        
        if not full_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ {company_code}")
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
        file_extension = full_path.suffix.lower()
        
        # –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å
        text_extensions = ['.txt', '.md', '.json', '.csv', '.html', '.xml', '.py', '.js', '.css']
        
        if file_extension in text_extensions:
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                return content, file_extension[1:]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –±–µ–∑ —Ç–æ—á–∫–∏
            except UnicodeDecodeError:
                return f"–§–∞–π–ª {file_path} –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ—á–∏—Ç–∞–Ω –∫–∞–∫ —Ç–µ–∫—Å—Ç", file_extension[1:]
        else:
            return f"–§–∞–π–ª {file_path} –∏–º–µ–µ—Ç –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω –∫–∞–∫ —Ç–µ–∫—Å—Ç", file_extension[1:]
    
    def _extract_company_and_query(self, query_text: str) -> Tuple[Optional[str], str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–¥–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –∏ —Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –∑–∞–ø—Ä–æ—Å–∞.
        
        Args:
            query_text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ None, —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞)
        """
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–º–ø–∞–Ω–∏–π
        companies = self.get_companies()
        company_codes = [company["code"] for company in companies]
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å–ª–æ–≤–∞
        words = query_text.split()
        
        if not words:
            return None, query_text
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –∫–æ–¥–æ–º –∫–æ–º–ø–∞–Ω–∏–∏
        first_word = words[0].upper()
        
        if first_word in company_codes:
            # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ - –∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ –∏ –æ—Å—Ç–∞–ª—å–Ω–æ–π –∑–∞–ø—Ä–æ—Å
            return first_word, " ".join(words[1:])
        
        # –ï—Å–ª–∏ –∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None –∏ –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        return None, query_text
    
    def _get_text_files(self, company_code: Optional[str] = None) -> List[Tuple[str, Path]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ –≤—Å–µ—Ö –∫–æ–º–ø–∞–Ω–∏–π.
        
        Args:
            company_code: –ö–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ None –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–∞–Ω–∏–π
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏, –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É)
        """
        text_files = []
        text_extensions = ['.txt', '.md', '.json', '.csv', '.html', '.xml', '.py', '.js', '.css']
        
        if company_code:
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏, –∏—â–µ–º —Ñ–∞–π–ª—ã —Ç–æ–ª—å–∫–æ –≤ —ç—Ç–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            company_dir = self.base_path / company_code
            if not company_dir.exists():
                logger.warning(f"–ö–æ–º–ø–∞–Ω–∏—è —Å –∫–æ–¥–æ–º {company_code} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return []
            
            # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏
            for ext in text_extensions:
                for file_path in company_dir.glob(f"**/*{ext}"):
                    if file_path.is_file():
                        text_files.append((company_code, file_path))
        else:
            # –ï—Å–ª–∏ –∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—â–µ–º —Ñ–∞–π–ª—ã –≤–æ –≤—Å–µ—Ö –∫–æ–º–ø–∞–Ω–∏—è—Ö
            companies = self.get_companies()
            
            for company in companies:
                company_code = company["code"]
                company_dir = self.base_path / company_code
                
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏
                for ext in text_extensions:
                    for file_path in company_dir.glob(f"**/*{ext}"):
                        if file_path.is_file():
                            text_files.append((company_code, file_path))
        
        return text_files
    
    def _chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è —á–∞–Ω–∫–∏.
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
            overlap: –†–∞–∑–º–µ—Ä –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ —Ç–µ–∫—Å—Ç–∞
        """
        if not text:
            return []
        
        chunks = []
        start = 0
        
        while start < len(text):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞
            end = min(start + chunk_size, len(text))
            
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫ –∏ –Ω–µ –¥–æ—Å—Ç–∏–≥–ª–∏ –∫–æ–Ω—Ü–∞ —Ç–µ–∫—Å—Ç–∞,
            # –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –∞–±–∑–∞—Ü–∞ –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            if end < len(text):
                # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –∞–±–∑–∞—Ü–∞ –ø–æ—Å–ª–µ end - overlap
                sentence_end = max(
                    text.rfind(". ", end - overlap, end),
                    text.rfind(".\n", end - overlap, end),
                    text.rfind("\n\n", end - overlap, end)
                )
                
                if sentence_end != -1:
                    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –º–µ—Å—Ç–æ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                    end = sentence_end + 1  # +1 —á—Ç–æ–±—ã –≤–∫–ª—é—á–∏—Ç—å —Ç–æ—á–∫—É –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—Ä–æ–∫–∏
            
            # –î–æ–±–∞–≤–ª—è–µ–º —á–∞–Ω–∫ –≤ —Å–ø–∏—Å–æ–∫
            chunks.append(text[start:end])
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞—á–∞–ª–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —á–∞–Ω–∫–∞ —Å —É—á–µ—Ç–æ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
            start = end - overlap if end - overlap > start else end
        
        return chunks
    
    def _get_embedding(self, text: str) -> List[float]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI API.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è embedding
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π (embedding)
            
        Raises:
            Exception: –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ embedding
        """
        if not OPENAI_API_KEY:
            raise ValueError("OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç API –∫–ª—é—á")
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤–æ–µ API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è embedding
            response = openai.embeddings.create(
                model="text-embedding-ada-002",
                input=text
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º embedding –∏–∑ –æ—Ç–≤–µ—Ç–∞
            embedding = response.data[0].embedding
            return embedding
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ embedding: {e}")
            raise
    
    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏.
        
        Args:
            a: –ü–µ—Ä–≤—ã–π –≤–µ–∫—Ç–æ—Ä
            b: –í—Ç–æ—Ä–æ–π –≤–µ–∫—Ç–æ—Ä
            
        Returns:
            –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ (–æ—Ç -1 –¥–æ 1)
        """
        a_norm = np.linalg.norm(a)
        b_norm = np.linalg.norm(b)
        
        if a_norm == 0 or b_norm == 0:
            return 0
        
        return np.dot(a, b) / (a_norm * b_norm)
    
    def _get_file_chunks_with_embeddings(self, company_code: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–æ–≤ —Å –∏—Ö embeddings.
        
        Args:
            company_code: –ö–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ None –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–∞–Ω–∏–π
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —á–∞–Ω–∫–∞—Ö –∏ –∏—Ö embeddings
        """
        if not OPENAI_AVAILABLE or not OPENAI_API_KEY:
            logger.warning("OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç API –∫–ª—é—á. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤.")
            return []
        
        chunks_with_embeddings = []
        text_files = self._get_text_files(company_code)
        
        for company_code, file_path in text_files:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∫—ç—à–µ
            rel_path = str(file_path.relative_to(self.base_path))
            cache_key = f"{company_code}:{rel_path}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–∞–π–ª –≤ –∫—ç—à–µ –∏ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ –æ–Ω
            file_mtime = file_path.stat().st_mtime
            
            if cache_key in self.embeddings_cache and self.embeddings_cache[cache_key]["mtime"] == file_mtime:
                # –ï—Å–ª–∏ —Ñ–∞–π–ª –≤ –∫—ç—à–µ –∏ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                chunks_with_embeddings.extend(self.embeddings_cache[cache_key]["chunks"])
                logger.debug(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {cache_key}")
                continue
            
            # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç –≤ –∫—ç—à–µ –∏–ª–∏ –æ–Ω –∏–∑–º–µ–Ω–∏–ª—Å—è, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ–≥–æ
            try:
                # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏
                chunks = self._chunk_text(content)
                
                # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ —Å –∏—Ö embeddings
                file_chunks = []
                
                for i, chunk in enumerate(chunks):
                    # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è —á–∞–Ω–∫–∞
                    embedding = self._get_embedding(chunk)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞–Ω–∫–µ
                    file_chunks.append({
                        "company_code": company_code,
                        "file_path": str(file_path),
                        "chunk_index": i,
                        "content": chunk,
                        "embedding": embedding
                    })
                
                # –î–æ–±–∞–≤–ª—è–µ–º —á–∞–Ω–∫–∏ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                chunks_with_embeddings.extend(file_chunks)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
                self.embeddings_cache[cache_key] = {
                    "mtime": file_mtime,
                    "chunks": file_chunks
                }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
                self._save_embeddings_cache()
                
                logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª {cache_key}, –ø–æ–ª—É—á–µ–Ω–æ {len(file_chunks)} —á–∞–Ω–∫–æ–≤")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        
        return chunks_with_embeddings
    
    def _find_relevant_chunks(self, query: str, company_code: Optional[str] = None, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞.
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            company_code: –ö–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ None –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—Å–µ–º –∫–æ–º–ø–∞–Ω–∏—è–º
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–∞—Ö
        """
        if not OPENAI_AVAILABLE or not OPENAI_API_KEY:
            logger.warning("OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç API –∫–ª—é—á. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.")
            return []
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = self._get_embedding(query)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ —Å –∏—Ö embeddings
            all_chunks = self._get_file_chunks_with_embeddings(company_code)
            
            if not all_chunks:
                logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞")
                return []
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–æ–º –∏ –∫–∞–∂–¥—ã–º —á–∞–Ω–∫–æ–º
            for chunk in all_chunks:
                chunk["similarity"] = self._cosine_similarity(query_embedding, chunk["embedding"])
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
            sorted_chunks = sorted(all_chunks, key=lambda x: x["similarity"], reverse=True)
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º top_k –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            return sorted_chunks[:top_k]
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {e}")
            return []
    
    def ask(self, query: str) -> str:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPT –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–æ–∏—Å–∫–∞.
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            –û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –∏ —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
        company_code, query_text = self._extract_company_and_query(query)
        
        # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø—É—Å—Ç–æ–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        if not query_text.strip():
            return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ—Å–ª–µ –∫–æ–¥–∞ –∫–æ–º–ø–∞–Ω–∏–∏."
        
        # –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω OpenAI API, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if OPENAI_AVAILABLE and OPENAI_API_KEY:
            return self._ask_with_gpt(query_text, company_code)
        else:
            # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            return self._simple_search(query_text, company_code)
    
    def _ask_with_gpt(self, query: str, company_code: Optional[str] = None) -> str:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPT.
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            company_code: –ö–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ None –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—Å–µ–º –∫–æ–º–ø–∞–Ω–∏—è–º
            
        Returns:
            –û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å
        """
        try:
            # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            relevant_chunks = self._find_relevant_chunks(query, company_code, top_k=8)
            
            if not relevant_chunks:
                if company_code:
                    return f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –≤ –∫–æ–º–ø–∞–Ω–∏–∏ {company_code}."
                else:
                    return "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞."
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            context = ""
            sources = set()
            
            for i, chunk in enumerate(relevant_chunks):
                context += f"–§—Ä–∞–≥–º–µ–Ω—Ç {i+1} (–∏–∑ {chunk['file_path']}):\n{chunk['content']}\n\n"
                sources.add(chunk['file_path'])
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ GPT
            system_prompt = """
            –í—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç Arttech Scriptor, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∫–Ω–∏–≥–∞—Ö.
            –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å —Ç–æ–ª—å–∫–æ –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
            –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å, —á–µ—Å—Ç–Ω–æ –ø—Ä–∏–∑–Ω–∞–π—Ç–µ—Å—å –≤ —ç—Ç–æ–º.
            –í–∞—à–∏ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏, —Ç–æ—á–Ω—ã–º–∏ –∏ —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏.
            """
            
            user_prompt = f"""
            –ö–æ–Ω—Ç–µ–∫—Å—Ç:
            {context}
            
            –í–æ–ø—Ä–æ—Å: {query}
            """
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ GPT
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo-16k",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å —Å –±–æ–ª—å—à–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –æ–∫–Ω–æ–º
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1500,
                temperature=0.7
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            answer = response.choices[0].message.content
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
            sources_info = "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏:\n" + "\n".join([f"- {src}" for src in sources])
            
            return answer + sources_info
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GPT: {e}")
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ GPT: {e}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫."
    
    def _simple_search(self, query: str, company_code: Optional[str] = None) -> str:
        """
        –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º.
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            company_code: –ö–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ None –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—Å–µ–º –∫–æ–º–ø–∞–Ω–∏—è–º
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞
        """
        results = []
        query_terms = query.lower().split()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
        if company_code:
            companies = [{"code": company_code}]
        else:
            companies = self.get_companies()
        
        for company in companies:
            company_code = company["code"]
            company_dir = self.base_path / company_code
            
            # –ü–æ–∏—Å–∫ –≤ meta.json
            meta_path = company_dir / "meta.json"
            if meta_path.exists():
                try:
                    with open(meta_path, 'r', encoding='utf-8') as f:
                        meta_data = json.load(f)
                    
                    meta_text = json.dumps(meta_data, ensure_ascii=False).lower()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ meta.json –≤—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –∑–∞–ø—Ä–æ—Å–∞
                    if all(term in meta_text for term in query_terms):
                        results.append(f"–ù–∞–π–¥–µ–Ω–æ –≤ meta.json –∫–æ–º–ø–∞–Ω–∏–∏ {meta_data.get('name', company_code)} ({company_code})")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ meta.json –¥–ª—è {company_code}: {e}")
            
            # –ü–æ–∏—Å–∫ –≤ summary.md
            summary_path = company_dir / "summary.md"
            if summary_path.exists():
                try:
                    with open(summary_path, 'r', encoding='utf-8') as f:
                        summary_content = f.read().lower()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ summary.md –≤—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –∑–∞–ø—Ä–æ—Å–∞
                    if all(term in summary_content for term in query_terms):
                        results.append(f"–ù–∞–π–¥–µ–Ω–æ –≤ summary.md –∫–æ–º–ø–∞–Ω–∏–∏ {company_code}")
                        
                        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞
                        term = query_terms[0]
                        pos = summary_content.find(term)
                        if pos >= 0:
                            start = max(0, pos - 100)
                            end = min(len(summary_content), pos + 100)
                            context = summary_content[start:end]
                            results.append(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: ...{context}...")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ summary.md –¥–ª—è {company_code}: {e}")
            
            # –ü–æ–∏—Å–∫ –≤ –¥—Ä—É–≥–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–∞—Ö
            for subdir in ["01_raw", "02_processed"]:
                subdir_path = company_dir / subdir
                if subdir_path.exists():
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º list() –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –≤ —Å–ø–∏—Å–∫–∏ –ø–µ—Ä–µ–¥ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º
                    text_files = list(subdir_path.glob("**/*.txt")) + list(subdir_path.glob("**/*.md"))
                    for file_path in text_files:
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                file_content = f.read().lower()
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ñ–∞–π–ª –≤—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –∑–∞–ø—Ä–æ—Å–∞
                            if all(term in file_content for term in query_terms):
                                rel_path = file_path.relative_to(company_dir)
                                results.append(f"–ù–∞–π–¥–µ–Ω–æ –≤ —Ñ–∞–π–ª–µ {rel_path} –∫–æ–º–ø–∞–Ω–∏–∏ {company_code}")
                                
                                # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞
                                term = query_terms[0]
                                pos = file_content.find(term)
                                if pos >= 0:
                                    start = max(0, pos - 100)
                                    end = min(len(file_content), pos + 100)
                                    context = file_content[start:end]
                                    results.append(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: ...{context}...")
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        
        if results:
            return "\n".join(results)
        else:
            if company_code:
                return f"–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –∫–æ–º–ø–∞–Ω–∏–∏ {company_code}."
            else:
                return "–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
    
    def search_content(self, query: str) -> str:
        """
        –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPT –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–æ–∏—Å–∫–∞.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞
        """
        return self.ask(query)
    
    def get_deadlines(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –±–ª–∏–∂–∞–π—à–∏—Ö –¥–µ–¥–ª–∞–π–Ω–æ–≤ –ø–æ –≤—Å–µ–º –∫–æ–º–ø–∞–Ω–∏—è–º.
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–µ–¥–ª–∞–π–Ω–∞—Ö
        """
        all_deadlines = []
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–º–ø–∞–Ω–∏–π
        companies = self.get_companies()
        
        for company in companies:
            company_code = company["code"]
            company_dir = self.base_path / company_code
            meta_path = company_dir / "meta.json"
            
            if meta_path.exists():
                try:
                    with open(meta_path, 'r', encoding='utf-8') as f:
                        meta_data = json.load(f)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ–¥–ª–∞–π–Ω—ã
                    deadlines = meta_data.get("deadlines", {})
                    
                    for deadline_name, deadline_date_str in deadlines.items():
                        try:
                            deadline_date = datetime.strptime(deadline_date_str, "%Y-%m-%d")
                            
                            all_deadlines.append({
                                "company_code": company_code,
                                "company_name": meta_data.get("name", company_code),
                                "deadline_name": deadline_name,
                                "deadline_date": deadline_date,
                                "days_left": (deadline_date - datetime.now()).days
                            })
                        except ValueError:
                            logger.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã –¥–ª—è –¥–µ–¥–ª–∞–π–Ω–∞ {deadline_name} –∫–æ–º–ø–∞–Ω–∏–∏ {company_code}")
                
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ meta.json –¥–ª—è {company_code}: {e}")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–µ–¥–ª–∞–π–Ω—ã –ø–æ –¥–∞—Ç–µ (–±–ª–∏–∂–∞–π—à–∏–µ —Å–Ω–∞—á–∞–ª–∞)
        all_deadlines.sort(key=lambda x: x["deadline_date"])
        
        return all_deadlines
    
    def get_user_profile(self, user_id: str = "default") -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Args:
            user_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        """
        # TODO: –í –±—É–¥—É—â–µ–º —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
        
        return {
            "user_id": user_id,
            "name": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å Arttech Scriptor",
            "role": "–†–µ–¥–∞–∫—Ç–æ—Ä",
            "assigned_companies": ["NIIPH", "ASIZ"],
            "last_activity": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def clarify_command(self, text: str) -> str:
        """
        –£—Ç–æ—á–Ω–µ–Ω–∏–µ –Ω–µ—è—Å–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPT.
        
        Args:
            text: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –£—Ç–æ—á–Ω—è—é—â–∏–π –æ—Ç–≤–µ—Ç
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ GPT
            system_prompt = """
            –í—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç Arttech Scriptor, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å –∫–æ–º–∞–Ω–¥–∞–º–∏.
            –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
            - /list - —Å–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π
            - /info <–∫–æ–¥> - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ meta.json
            - /get <–∫–æ–¥> <—Ñ–∞–π–ª> - –≤—ã–¥–∞—á–∞ —Ñ–∞–π–ª–æ–≤
            - /ask [<–∫–æ–¥>] <–≤–æ–ø—Ä–æ—Å> - GPT-–ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ
            - /deadlines - –±–ª–∏–∂–∞–π—à–∏–µ —Å—Ä–æ–∫–∏
            - /my - –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
            –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ–∏–∑–Ω–µ—Å —Ñ—Ä–∞–∑—É, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ –±—ã–ª–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –∫–∞–∫ –∫–æ–º–∞–Ω–¥–∞.
            –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫—É—é –∫–æ–º–∞–Ω–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å, –≤–µ—Ä–æ—è—Ç–Ω–æ, —Ö–æ—Ç–µ–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å,
            –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –∫–æ–º–∞–Ω–¥—ã.
            """
            
            user_prompt = f"""
            –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ–∏–∑–Ω–µ—Å: "{text}"
            
            –ö–∞–∫—É—é –∫–æ–º–∞–Ω–¥—É –æ–Ω, –≤–µ—Ä–æ—è—Ç–Ω–æ, —Ö–æ—Ç–µ–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å? –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç.
            """
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ GPT
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=150,
                temperature=0.7
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            answer = response.choices[0].message.content
            
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∫–æ–º–∞–Ω–¥—É: '{text}'.\n\n{answer}"
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Ç–æ—á–Ω–µ–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã: {e}")
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∫–æ–º–∞–Ω–¥—É: '{text}'. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã: /list, /info, /get, /ask, /deadlines, /my"
    
    def process_command(self, command: str) -> str:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Args:
            command: –ö–æ–º–∞–Ω–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã
            
        Raises:
            UnknownCommandError: –ï—Å–ª–∏ –∫–æ–º–∞–Ω–¥–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞
        """
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        command = command.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –∫–æ–º–∞–Ω–¥–∞ —Å "/"
        if not command.startswith("/"):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –∫–æ–º–∞–Ω–¥—É
            command_lower = command.lower()
            
            if "—Å–ø–∏—Å–æ–∫" in command_lower or "–∫–æ–º–ø–∞–Ω–∏–∏" in command_lower:
                return self.process_command("/list")
            elif "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è" in command_lower and any(company["code"].lower() in command_lower for company in self.get_companies()):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏
                for company in self.get_companies():
                    if company["code"].lower() in command_lower:
                        return self.process_command(f"/info {company['code']}")
            elif "—Ñ–∞–π–ª" in command_lower and any(company["code"].lower() in command_lower for company in self.get_companies()):
                # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–æ–º–∞–Ω–¥–∞ /get, –Ω–æ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                pass
            elif "–≤–æ–ø—Ä–æ—Å" in command_lower or "—Å–ø—Ä–æ—Å–∏—Ç—å" in command_lower:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∫–æ–º–∞–Ω–¥—É /ask
                return self.process_command(f"/ask {command}")
            elif "–¥–µ–¥–ª–∞–π–Ω" in command_lower or "—Å—Ä–æ–∫" in command_lower:
                return self.process_command("/deadlines")
            elif "–ø—Ä–æ—Ñ–∏–ª—å" in command_lower or "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" in command_lower:
                return self.process_command("/my")
            
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∫–æ–º–∞–Ω–¥—É, –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
            raise UnknownCommandError(f"–ö–æ–º–∞–Ω–¥–∞ –¥–æ–ª–∂–Ω–∞ –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å —Å–∏–º–≤–æ–ª–∞ '/'. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã: /list, /info, /get, /ask, /deadlines, /my")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –∫–æ–º–∞–Ω–¥—É –Ω–∞ —á–∞—Å—Ç–∏
        parts = command.split()
        cmd = parts[0].lower()
        
        try:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /list
            if cmd == "/list":
                companies = self.get_companies()
                if not companies:
                    return "–í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–º–ø–∞–Ω–∏–π."
                
                result = "–°–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π:\n\n"
                for company in companies:
                    result += f"üìÅ {company['code']} - {company['name']}\n"
                    result += f"   –°—Ç–∞—Ç—É—Å: {company['status']}\n"
                    if company['description']:
                        result += f"   {company['description']}\n"
                    result += "\n"
                
                return result
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /info
            elif cmd == "/info":
                if len(parts) < 2:
                    return "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏. –ü—Ä–∏–º–µ—Ä: /info NIIPH"
                
                company_code = parts[1].upper()
                info = self.get_company_info(company_code)
                
                result = f"üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–ø–∞–Ω–∏–∏ {info.get('name', company_code)} ({company_code}):\n\n"
                result += f"–°—Ç–∞—Ç—É—Å: {info.get('status', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n"
                result += f"–û–ø–∏—Å–∞–Ω–∏–µ: {info.get('short_description', '')}\n"
                
                if 'keywords' in info and info['keywords']:
                    result += f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(info['keywords'])}\n"
                
                if 'deadlines' in info and info['deadlines']:
                    result += "\n–î–µ–¥–ª–∞–π–Ω—ã:\n"
                    for name, date in info['deadlines'].items():
                        result += f"- {name}: {date}\n"
                
                if 'structure' in info:
                    result += "\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞:\n"
                    result += f"- –°—ã—Ä—ã–µ —Ñ–∞–π–ª—ã: {info['structure']['raw_files']}\n"
                    result += f"- –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {info['structure']['processed_files']}\n"
                    result += f"- –ê—Å—Å–µ—Ç—ã: {info['structure']['assets']}\n"
                
                if info.get('summary_exists', False):
                    result += "\n–î–æ—Å—Ç—É–ø–Ω–∞ —Å–≤–æ–¥–∫–∞ (summary.md). –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /get –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞.\n"
                
                if 'last_updated' in info:
                    result += f"\n–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {info['last_updated']}\n"
                
                return result
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /get
            elif cmd == "/get":
                if len(parts) < 3:
                    return "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏ –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É. –ü—Ä–∏–º–µ—Ä: /get NIIPH summary.md"
                
                company_code = parts[1].upper()
                file_path = " ".join(parts[2:])  # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —á–∞—Å—Ç–∏ –∫–∞–∫ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
                
                content, file_type = self.get_file_content(company_code, file_path)
                
                result = f"üìÑ –§–∞–π–ª: {file_path} ({file_type})\n"
                result += f"–ö–æ–º–ø–∞–Ω–∏—è: {company_code}\n\n"
                result += "```\n"
                result += content
                result += "\n```"
                
                return result
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /ask
            elif cmd == "/ask":
                if len(parts) < 2:
                    return "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –≤–æ–ø—Ä–æ—Å. –ü—Ä–∏–º–µ—Ä: /ask –ö–∞–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ —Å–≤—è–∑–∞–Ω—ã —Å —Ö–∏–º–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç—å—é?"
                
                query = " ".join(parts[1:])
                result = self.ask(query)
                
                return f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'\n\n{result}"
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /deadlines
            elif cmd == "/deadlines":
                deadlines = self.get_deadlines()
                
                if not deadlines:
                    return "–î–µ–¥–ª–∞–π–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
                
                result = "‚è∞ –ë–ª–∏–∂–∞–π—à–∏–µ –¥–µ–¥–ª–∞–π–Ω—ã:\n\n"
                
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–µ–¥–ª–∞–π–Ω—ã –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º
                deadlines_by_company = {}
                for deadline in deadlines:
                    company_code = deadline["company_code"]
                    if company_code not in deadlines_by_company:
                        deadlines_by_company[company_code] = []
                    deadlines_by_company[company_code].append(deadline)
                
                # –í—ã–≤–æ–¥–∏–º –¥–µ–¥–ª–∞–π–Ω—ã –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º
                for company_code, company_deadlines in deadlines_by_company.items():
                    company_name = company_deadlines[0]["company_name"]
                    result += f"üìÅ {company_name} ({company_code}):\n"
                    
                    for deadline in company_deadlines:
                        days_left = deadline["days_left"]
                        date_str = deadline["deadline_date"].strftime("%d.%m.%Y")
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ä–æ—á–Ω–æ—Å—Ç–∏
                        if days_left < 0:
                            emoji = "üî¥"  # –ü—Ä–æ—Å—Ä–æ—á–µ–Ω–æ
                        elif days_left < 7:
                            emoji = "üü†"  # –ú–µ–Ω–µ–µ –Ω–µ–¥–µ–ª–∏
                        elif days_left < 30:
                            emoji = "üü°"  # –ú–µ–Ω–µ–µ –º–µ—Å—è—Ü–∞
                        else:
                            emoji = "üü¢"  # –ë–æ–ª–µ–µ –º–µ—Å—è—Ü–∞
                        
                        if days_left < 0:
                            days_text = f"–ø—Ä–æ—Å—Ä–æ—á–µ–Ω–æ –Ω–∞ {abs(days_left)} –¥–Ω."
                        else:
                            days_text = f"–æ—Å—Ç–∞–ª–æ—Å—å {days_left} –¥–Ω."
                        
                        result += f"  {emoji} {deadline['deadline_name']}: {date_str} ({days_text})\n"
                    
                    result += "\n"
                
                return result
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /my
            elif cmd == "/my":
                profile = self.get_user_profile()
                
                result = "üë§ –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n\n"
                result += f"–ò–º—è: {profile['name']}\n"
                result += f"–†–æ–ª—å: {profile['role']}\n"
                result += f"–ù–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏: {', '.join(profile['assigned_companies'])}\n"
                result += f"–ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {profile['last_activity']}\n"
                
                # TODO: –í –±—É–¥—É—â–µ–º –¥–æ–±–∞–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                
                return result
            
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞
            else:
                raise UnknownCommandError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {cmd}. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã: /list, /info, /get, /ask, /deadlines, /my")
        
        except FileNotFoundError as e:
            return f"–û—à–∏–±–∫–∞: {str(e)}"
        except ValueError as e:
            return f"–û—à–∏–±–∫–∞: {str(e)}"
        except Exception as e:
            logger.error(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã: {str(e)}"


# –ï—Å–ª–∏ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω –Ω–∞–ø—Ä—è–º—É—é, –∞ –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
if __name__ == "__main__":
    import sys
    import argparse
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser(description="Arttech Scriptor - –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∫–Ω–∏–≥")
    parser.add_argument("--voice", type=str, help="–ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É —Å –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥–æ–π")
    parser.add_argument("--mic", type=int, help="–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö")
    parser.add_argument("command", nargs="*", help="–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
    
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    args = parser.parse_args()
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã
    if args.voice or args.mic is not None:
        result = process_voice_command(audio_path=args.voice, mic_duration=args.mic)
        print(result)
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    elif args.command:
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        assistant = ArttechScriptor()
        command = " ".join(args.command)
        result = assistant.process_command(command)
        print(result)
    else:
        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        print("Arttech Scriptor - –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –∫–Ω–∏–≥–∞–º–∏")
        print("–í–≤–µ–¥–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞")
        print("–î–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --voice <–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É> –∏–ª–∏ --mic <–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å>")
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        assistant = ArttechScriptor()
        
        while True:
            command = input("> ")
            
            if command.lower() in ["exit", "quit", "–≤—ã—Ö–æ–¥"]:
                break
            
            try:
                result = assistant.process_command(command)
                print(result)
            except UnknownCommandError:
                # –ï—Å–ª–∏ –∫–æ–º–∞–Ω–¥–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º GPT –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è
                clarification = assistant.clarify_command(command)
                print(clarification)
